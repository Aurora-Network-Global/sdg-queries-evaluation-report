
@article{bornmann_what_2013,
	title = {What is societal impact of research and how can it be assessed? a literature survey},
	volume = {64},
	rights = {© 2012 {ASIS}\&T},
	issn = {1532-2890},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/asi.22803},
	doi = {10.1002/asi.22803},
	shorttitle = {What is societal impact of research and how can it be assessed?},
	abstract = {Since the 1990s, the scope of research evaluations becomes broader as the societal products (outputs), societal use (societal references), and societal benefits (changes in society) of research come into scope. Society can reap the benefits of successful research studies only if the results are converted into marketable and consumable products (e.g., medicaments, diagnostic tools, machines, and devices) or services. A series of different names have been introduced which refer to the societal impact of research: third stream activities, societal benefits, societal quality, usefulness, public values, knowledge transfer, and societal relevance. What most of these names are concerned with is the assessment of social, cultural, environmental, and economic returns (impact and effects) from results (research output) or products (research outcome) of publicly funded research. This review intends to present existing research on and practices employed in the assessment of societal impact in the form of a literature survey. The objective is for this review to serve as a basis for the development of robust and reliable methods of societal impact measurement.},
	pages = {217--233},
	number = {2},
	journaltitle = {Journal of the American Society for Information Science and Technology},
	author = {Bornmann, Lutz},
	urldate = {2019-07-12},
	date = {2013},
	year = {2013},
	journal = {Journal of the American Society for Information Science and Technology},
	langid = {english},
	keywords = {sciences, social},
	file = {Full Text PDF:C\:\\Users\\mauri\\Zotero\\storage\\RA8Z382L\\Bornmann - 2013 - What is societal impact of research and how can it.pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\B5VP2F2C\\asi.html:text/html}
}

@book{carley_social_2019,
	title = {Social Impact Assessment And Monitoring: A Guide To The Literature},
	isbn = {978-1-00-031177-8},
	shorttitle = {Social Impact Assessment And Monitoring},
	abstract = {This systematic, critical review of more than 600 recent publications in social impact assessment ({SIA}) and related fields is based on the authors' belief that {SIA} is more than an analytical technique--it is also a logical and timely response to our ever-growing need for more and better information to facilitate decision making in an increasingly c},
	pagetotal = {218},
	publisher = {Routledge},
	author = {Carley, Michael J. and Bustelo, Eduardo},
	date = {2019-05-28},
	year = {2019},
	langid = {english},
	note = {Google-Books-{ID}: {lqiaDwAAQBAJ}},
	keywords = {Political Science / General}
}

@article{spaapen_introducing_2011,
	title = {Introducing 'productive interactions' in social impact assessment},
	volume = {20},
	issn = {0958-2029, 1471-5449},
	url = {https://academic.oup.com/rev/article-lookup/doi/10.3152/095820211X12941371876742},
	doi = {10.3152/095820211X12941371876742},
	pages = {211--218},
	number = {3},
	journaltitle = {Research Evaluation},
	author = {Spaapen, J. and van Drooge, L.},
	urldate = {2019-07-09},
	date = {2011-09-01},
	langid = {english},
	file = {Spaapen en van Drooge - 2011 - Introducing 'productive interactions' in social im.pdf:C\:\\Users\\mauri\\Zotero\\storage\\JKYEG2RE\\Spaapen en van Drooge - 2011 - Introducing 'productive interactions' in social im.pdf:application/pdf}
}

@article{spaapen_siampi_nodate,
	title = {{SIAMPI} 230330 final report},
	pages = {36},
	author = {Spaapen, Jack and van Drooge, Leonie and Propp, Tilo},
	langid = {english},
	file = {Spaapen e.a. - SIAMPI 230330 final report.pdf:C\:\\Users\\mauri\\Zotero\\storage\\35LX9E82\\Spaapen e.a. - SIAMPI 230330 final report.pdf:application/pdf}
}

@article{khalili_semantically_nodate,
	title = {Semantically Mapping Science ({SMS}) Platform},
	abstract = {Up to now, {STI} (Science, Technology, Innovation) studies are either rich but small scale (qualitative case studies) or large scale and under-complex – because they generally use only a single dataset like Patstat, Scopus, {WoS} (Web of Science), {OECD} {STI} indicators, etc., and therefore deploying only a few variables – determined by the data available. However, progress in the {STI} research ﬁeld (and the social sciences in general) depends in our view on the ability to do large-scale studies with often many variables speciﬁed by relevant theories. There is a need for studies which are at the same time big and rich. The aim of the Semantically Mapping Science ({SMS}) platform is to enable enriching and integration of heterogeneous data, ranging from tabular statistical data to unstructured data found on the Web, in order to exploit the huge amount of data that are ‘out there’ in an innovative and meaningful way.},
	pages = {6},
	author = {Khalili, Ali and de Graaf, Klaas Andries and van Harmelen, Frank},
	langid = {english},
	file = {Khalili e.a. - Semantically Mapping Science (SMS) Platform.pdf:C\:\\Users\\mauri\\Zotero\\storage\\KWZMAPFS\\Khalili e.a. - Semantically Mapping Science (SMS) Platform.pdf:application/pdf}
}

@article{borner_modeling_2011,
	title = {Modeling science: studying the structure and dynamics of science},
	volume = {89},
	issn = {1588-2861},
	url = {https://doi.org/10.1007/s11192-011-0429-3},
	doi = {10.1007/s11192-011-0429-3},
	shorttitle = {Modeling science},
	pages = {347--348},
	number = {1},
	journaltitle = {Scientometrics},
	shortjournal = {Scientometrics},
	author = {Börner, Katy and Glänzel, Wolfgang and Scharnhorst, Andrea and van den Besselaar, Peter},
	urldate = {2019-07-08},
	date = {2011-10-01},
	langid = {english},
	file = {Springer Full Text PDF:C\:\\Users\\mauri\\Zotero\\storage\\HS6G4WAE\\Börner e.a. - 2011 - Modeling science studying the structure and dynam.pdf:application/pdf}
}

@article{erdt_altmetrics:_2016,
	title = {Altmetrics: an analysis of the state-of-the-art in measuring research impact on social media},
	volume = {109},
	issn = {0138-9130, 1588-2861},
	url = {http://link.springer.com/10.1007/s11192-016-2077-0},
	doi = {10.1007/s11192-016-2077-0},
	shorttitle = {Altmetrics},
	abstract = {Altmetrics is an emergent research area whereby social media is applied as a source of metrics to assess scholarly impact. In the last few years, the interest in altmetrics has grown, giving rise to many questions regarding their potential beneﬁts and challenges. This paper aims to address some of these questions. First, we provide an overview of the altmetrics landscape, comparing tool features, social media data sources, and social media events provided by altmetric aggregators. Second, we conduct a systematic review of the altmetrics literature. A total of 172 articles were analysed, revealing a steady rise in altmetrics research since 2011. Third, we analyse the results of over 80 studies from the altmetrics literature on two major research topics: cross-metric validation and coverage of altmetrics. An aggregated percentage coverage across studies on 11 data sources shows that Mendeley has the highest coverage of about 59 \% across 15 studies. A meta-analysis across more than 40 cross-metric validation studies shows overall a weak correlation (ranging from 0.08 to 0.5) between altmetrics and citation counts, conﬁrming that altmetrics do indeed measure a different kind of research impact, thus acting as a complement rather than a substitute to traditional metrics. Finally, we highlight open challenges and issues facing altmetrics and discuss future research areas.},
	pages = {1117--1166},
	number = {2},
	journaltitle = {Scientometrics},
	author = {Erdt, Mojisola and Nagarajan, Aarthy and Sin, Sei-Ching Joanna and Theng, Yin-Leng},
	urldate = {2019-07-08},
	date = {2016-11},
	langid = {english},
	file = {Erdt e.a. - 2016 - Altmetrics an analysis of the state-of-the-art in.pdf:C\:\\Users\\mauri\\Zotero\\storage\\9YYV273R\\Erdt e.a. - 2016 - Altmetrics an analysis of the state-of-the-art in.pdf:application/pdf}
}

@article{kim_latest_2018,
	title = {Latest trends in innovative global scholarly journal publication and distribution platforms},
	volume = {5},
	issn = {2288-8063, 2288-7474},
	url = {http://escienceediting.org/journal/view.php?doi=10.6087/kcse.133},
	doi = {10.6087/kcse.133},
	abstract = {This review article presents the latest trends in innovative global scholarly journal publication and distribution platforms, with implications for local journals. Changes have taken place in distribution policies, as pre-publication distribution has become a viable option, and for post-publication distribution, public access or mandatory open access policies have been introduced for articles supported by public or governmental funds. New formats of articles include graphical abstracts, interactive {PDFs}, the application of semantic enhancements, and the utilization of research data, social networking sites, such as Mendeley and {ResearchGate}, have become common sites for information exchange. Altmetrics have been adopted to complement traditional journal metrics. {PubMed} Central, F1000Research, {KoreaMed} Synapse, and {ScienceCentral} have been introduced as innovative full-text scholarly journal distribution systems. To publish web-based scholarly journals, it is necessary to adopt an open platform and to explore options such as an author profile database, an online collaborative editing module, and Crossref text and data mining services. To maximize the influence of local journals, it is necessary to integrate various external tools, such as researcher {ID}, research data, social media, and altmetrics services.},
	pages = {100--112},
	number = {2},
	journaltitle = {Science Editing},
	author = {Kim, Soon and Chung, Eunkyung and Lee, Jae Yun},
	urldate = {2019-07-08},
	date = {2018-08-20},
	langid = {english},
	file = {Kim e.a. - 2018 - Latest trends in innovative global scholarly journ.pdf:C\:\\Users\\mauri\\Zotero\\storage\\THR22CIE\\Kim e.a. - 2018 - Latest trends in innovative global scholarly journ.pdf:application/pdf}
}

@article{barilan_peer_2018,
	title = {Peer review, bibliometrics and altmetrics - Do we need them all?},
	volume = {55},
	rights = {Copyright © 2018 by Association for Information Science and Technology},
	issn = {2373-9231},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/pra2.2018.14505501073},
	doi = {10.1002/pra2.2018.14505501073},
	abstract = {This panel will present views and critical reflections on peer review, bibliometrics and altmetrics against the background of the latest developments and critique of the scientific system (e.g., replication crisis, {DORA}, open science, data manipulation). Peer review is the oldest form of monitoring the scientific process and research outcomes and is sometimes considered as the gold standard for evaluating quality. However, it also has its drawbacks; therefore, new forms of peer review are being explored. Bibliometrics, comparative statistics based on publication and citation counts, was introduced as a more objective evaluation method, which is applicable on meso and macro levels of research producing units but is not without problems either. Citation counts as a proxy of quality; the impact factor and the h-index are some of the most controversial subjects of research evaluation today. The newest addition to the evaluation toolbox are altmetrics, impact measures based mainly on social media activity. Altmetrics have pros and cons as well. None of the measuring devices is perfect, and rather than replacing they complement each other. By drawing on indicators from all three aspects of research evaluation, negative and adverse effects are limited.},
	pages = {653--656},
	number = {1},
	journaltitle = {Proceedings of the Association for Information Science and Technology},
	author = {Bar‐Ilan, Judit and Haustein, Stefanie and Milojević, Staša and Peters, Isabella and Wolfram, Dietmar},
	urldate = {2019-07-08},
	date = {2018},
	langid = {english},
	keywords = {altmetrics, bibliometrics, Peer review, research evaluation},
	file = {Full Text PDF:C\:\\Users\\mauri\\Zotero\\storage\\HFQTTJ3X\\Bar‐Ilan e.a. - 2018 - Peer review, bibliometrics and altmetrics - Do we .pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\GXRHWDVS\\pra2.2018.html:text/html}
}

@article{karanatsiou_bibliometrics_2017,
	title = {Bibliometrics and altmetrics literature review},
	url = {/insight/content/doi/10.1108/PMM-08-2016-0036/full/html},
	doi = {10.1108/PMM-08-2016-0036},
	abstract = {The purpose of this paper is to present the evolution in notions from bibliometrics to altmetrics and confront them taking into consideration specific criteria. The objective of this paper is to present the evolution of research, regarding the above fields, the study of metrics and indicators used, and the strength and weaknesses resulting from the current literature. Furthermore, the authors present the manipulation techniques for both fields as their main weakness, as well as further key points, analyzing the alternative options of bibliometrics and altmetrics.,First, the authors present the evolution of the literature, concerning the specific field and metrics used, following with a brief description of basic indicators related to the field of bibliometrics (journal impact factor ({JIF}), eigenfactor, article influence score and h-index) discussing their advantages and disadvantages. In the second part, the authors describe altmetrics and present the differences with bibliometrics.,Both bibliometrics and altmetrics remain weak indicators as fraught with disadvantages with manipulation being the greatest of all. Nevertheless, the combination of the two is proposed in order to export safer conclusions on assessing the impact. Regarding the manipulation there is yet not a clean technique to eliminate manipulation. In specific, regarding bibliometrics, the manipulation of indicators refers only to the human factor intervention. The theoretical implication of this study constitutes of collecting the relevant literature regarding scientific indicators.,We must consider the study of new indicators, which combine metrics and methodologies used in both bibliometrics and altmetrics. The theoretical implication of this study constitutes of collecting the relevant literature regarding scientific indicators. Therefore, researchers are encouraged to test the proposed propositions further.,The practical contribution, on the other side, provides scholars with the knowledge of how making their work more accessible, increasing their impact.,The authors add to the originality by providing a framework of the relevant literature for bibliometrics and altmetrics for future researchers. The authors describe altmetrics and present the differences with bibliometrics. The authors conclude the research with the implications of the conducted analysis and the potential directions for future research. Regarding manipulation, the authors provide with the techniques so researchers are aware of the methods in order to protect their academic profile.},
	journaltitle = {Performance Measurement and Metrics},
	author = {Karanatsiou, Dimitra and Misirlis, Nikolaos and Vlachopoulou, Maro},
	urldate = {2019-07-08},
	date = {2017-04-10},
	langid = {english},
	file = {Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\N9KYH65A\\html.html:text/html;Karanatsiou e.a. - 2017 - Bibliometrics and altmetrics literature review Pe.pdf:C\:\\Users\\mauri\\Zotero\\storage\\A5B2QX3K\\Karanatsiou e.a. - 2017 - Bibliometrics and altmetrics literature review Pe.pdf:application/pdf}
}

@article{nicholas_early_2018,
	title = {Early Career Researchers' Quest for Reputation in the Digital Age},
	url = {https://utpjournals.press/doi/abs/10.3138/jsp.49.4.01},
	doi = {10.3138/jsp.49.4.01},
	abstract = {The purpose of this article is twofold: a) to describe and compare methods of early career researcher ({ECR}) assessment/appraisal; b) to explain how {ECRs} build, showcase, and monitor their reputatio...},
	journaltitle = {Journal of Scholarly Publishing},
	author = {Nicholas, David and Herman, Eti and Xu, Jie and Boukacem-Zeghmouri, Chérifa and Abdullah, Abrizah and Watkinson, Anthony and Świgoń, Marzena and Rodríguez-Bravo, Blanca},
	urldate = {2019-07-08},
	date = {2018-07-26},
	langid = {english},
	file = {Full Text PDF:C\:\\Users\\mauri\\Zotero\\storage\\PHE55L8F\\Nicholas e.a. - 2018 - Early Career Researchers' Quest for Reputation in .pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\GWA77JDS\\jsp.49.4.html:text/html}
}

@article{carlson_quantifying_2020,
	title = {Quantifying and contextualizing the impact of {bioRxiv} preprints through automated social media audience segmentation},
	volume = {18},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000860},
	doi = {10.1371/journal.pbio.3000860},
	abstract = {Engagement with scientific manuscripts is frequently facilitated by Twitter and other social media platforms. As such, the demographics of a paper's social media audience provide a wealth of information about how scholarly research is transmitted, consumed, and interpreted by online communities. By paying attention to public perceptions of their publications, scientists can learn whether their research is stimulating positive scholarly and public thought. They can also become aware of potentially negative patterns of interest from groups that misinterpret their work in harmful ways, either willfully or unintentionally, and devise strategies for altering their messaging to mitigate these impacts. In this study, we collected 331,696 Twitter posts referencing 1,800 highly tweeted {bioRxiv} preprints and leveraged topic modeling to infer the characteristics of various communities engaging with each preprint on Twitter. We agnostically learned the characteristics of these audience sectors from keywords each user’s followers provide in their Twitter biographies. We estimate that 96\% of the preprints analyzed are dominated by academic audiences on Twitter, suggesting that social media attention does not always correspond to greater public exposure. We further demonstrate how our audience segmentation method can quantify the level of interest from nonspecialist audience sectors such as mental health advocates, dog lovers, video game developers, vegans, bitcoin investors, conspiracy theorists, journalists, religious groups, and political constituencies. Surprisingly, we also found that 10\% of the preprints analyzed have sizable ({\textgreater}5\%) audience sectors that are associated with right-wing white nationalist communities. Although none of these preprints appear to intentionally espouse any right-wing extremist messages, cases exist in which extremist appropriation comprises more than 50\% of the tweets referencing a given preprint. These results present unique opportunities for improving and contextualizing the public discourse surrounding scientific research.},
	pages = {e3000860},
	number = {9},
	journaltitle = {{PLOS} Biology},
	shortjournal = {{PLOS} Biology},
	author = {Carlson, Jedidiah and Harris, Kelley},
	urldate = {2020-09-30},
	date = {2020-09-22},
	year = {2020},
	journal = {{PLOS} Biology},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Altmetrics, Social media, Peer review, Scientists, Twitter, Social systems, Social networks, Cognitive neuroscience},
	file = {Carlson_Harris_2020_Quantifying and contextualizing the impact of bioRxiv preprints through.pdf:C\:\\Users\\mauri\\Zotero\\storage\\3UVMHVUU\\Carlson_Harris_2020_Quantifying and contextualizing the impact of bioRxiv preprints through.pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\WI58SURT\\article.html:text/html}
}

@article{seppanen_co-citation_2020,
	title = {Co-Citation Percentile Rank and {JYUcite}: a new network-standardized output-level citation influence metric and its implementation using Dimensions {API}},
	rights = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), {CC} {BY} 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {10.1101/2020.09.23.310052},
	doi = {10.1101/2020.09.23.310052},
	shorttitle = {Co-Citation Percentile Rank and {JYUcite}},
	abstract = {{\textless}p{\textgreater}Judging value of scholarly outputs quantitatively remains a difficult but unavoidable challenge. Most of the proposed solutions suffer from three fundamental shortcomings: they involve i) the concept of journal, in one way or another, ii) calculating arithmetic averages from extremely skewed distributions, and iii) binning data by calendar year. Here, we introduce a new metric Co-citation Percentile Rank ({CPR}), that relates the current citation rate of the target output taken at resolution of days since first citable, to the distribution of current citation rates of outputs in its co-citation set, as its percentile rank in that set. We explore some of its properties with an example dataset of all scholarly outputs from University of Jyväskylä spanning multiple years and disciplines. We also demonstrate how {CPR} can be efficiently implemented with Dimensions database {API}, and provide a publicly available web resource {JYUcite}, allowing anyone to retrieve {CPR} value for any output that has a {DOI} and is indexed in the Dimensions database. Finally, we discuss how {CPR} remedies failures of the Relative Citation Ratio ({RCR}), and remaining issues in situations where {CPR} too could potentially lead to biased judgement of value.{\textless}/p{\textgreater}},
	pages = {2020.09.23.310052},
	journaltitle = {{bioRxiv}},
	author = {Seppänen, Janne-Tuomas and Värri, Hanna and Ylönen, Irene},
	urldate = {2020-09-30},
	date = {2020-09-23},
	langid = {english},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results; http://web.archive.org/web/20200930101001/https://www.biorxiv.org/content/10.1101/2020.09.23.310052v1},
	file = {Seppänen et al_2020_Co-Citation Percentile Rank and JYUcite.pdf:C\:\\Users\\mauri\\Zotero\\storage\\Y5QXCF4F\\Seppänen et al_2020_Co-Citation Percentile Rank and JYUcite.pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\VZIZHQUX\\2020.09.23.html:text/html}
}

@article{armitage_mapping_2020,
	title = {Mapping scholarly publications related to the Sustainable Development Goals: Do independent bibliometric approaches get the same results?},
	volume = {1},
	issn = {2641-3337},
	url = {10.1162/qss_a_00071},
	doi = {10.1162/qss_a_00071},
	shorttitle = {Mapping scholarly publications related to the Sustainable Development Goals},
	abstract = {Many research and higher education institutions are interested in their contribution to achieving the United Nation’s Sustainable Development Goals ({SDG}). Commercial services from Elsevier and Times Higher Education are addressing this by developing bibliometric queries for measuring {SDG}-related publications and {SDG} university rankings. However, such services should be evaluated carefully before use due to the challenging nature of interpreting the {SDGs}, delimiting relevance, and building queries. The aim of this bibliometric study was to build independent queries to find scholarly publications related to {SDG} 1, {SDG} 2, {SDG} 3, {SDG} 7, {SDG} 13, and {SDG} 14 using a consistent method based on {SDG} targets and indicators (the Bergen approach), and compare sets of publications retrieved by the Bergen and Elsevier approaches. Our results show that approach made a large difference, with little overlap in publications retrieved by the two approaches. We further demonstrate that different approaches can alter resulting country rankings. Choice of search terms, how they are combined, and query structure play a role, related to differing interpretations of the {SDGs} and viewpoints on relevance. Our results suggest that currently available {SDG} rankings and tools should be used with caution at their current stage of development.},
	pages = {1092--1108},
	number = {3},
	journaltitle = {Quantitative Science Studies},
	shortjournal = {Quantitative Science Studies},
	author = {Armitage, Caroline S. and Lorenz, Marta and Mikki, Susanne},
	urldate = {2021-04-15},
	date = {2020-08-01},
	year = {2020},
	journal = {Quantitative Science Studies},
	file = {Armitage et al_2020_Mapping scholarly publications related to the Sustainable Development Goals.pdf:C\:\\Users\\mauri\\Zotero\\storage\\IR885H53\\Armitage et al_2020_Mapping scholarly publications related to the Sustainable Development Goals.pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\32I2DM9J\\Mapping-scholarly-publications-related-to-the.html:text/html}
}

@article{drooge_evaluating_2010,
	title = {Evaluating the societal relevance of academic research: A guide},
	url = {https://pure.knaw.nl/portal/en/publications/evaluating-the-societal-relevance-of-academic-research-a-guide},
	shorttitle = {Evaluating the societal relevance of academic research},
	author = {Drooge, L. van and Besselaar, P. van den and Elsen, G. M. F. and Haas, M. de and Heuvel, J. J. van den and Brink, H. Maassen van den and Meulen, B. van der and Spaapen, J. B. and Westenbrink, R.},
	urldate = {2021-04-15},
	date = {2010},
	year = {2010},
	journal = {EriC-Evaluating Research in Context},
	note = {Publisher: {ERiC}-Evaluating Research in Context},
	file = {Drooge et al_2010_Evaluating the societal relevance of academic research.pdf:C\:\\Users\\mauri\\Zotero\\storage\\K6F9WDSW\\Drooge et al_2010_Evaluating the societal relevance of academic research.pdf:application/pdf;Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\N7HP3MQA\\evaluating-the-societal-relevance-of-academic-research-a-guide.html:text/html}
}

@misc{vanderfeesten_text_2020,
	title = {Text Analyses of Survey Data on "Mapping Research Output to the Sustainable Development Goals ({SDGs})"},
	url = {https://zenodo.org/record/3832090},
	abstract = {This package contains data on five text analysis types (term extraction, contract analysis, topic modeling, network mapping), based on the survey data where researchers selected research output that are related to the 17 Sustainable Development Goals ({SDGs}). This is used as input to improve the current {SDG} classification model v4.0 to v5.0 Sustainable Development Goals are the 17 global challenges set by the United Nations. Within each of the goals specific targets and indicators are mentioned to monitor the progress of reaching those goals by 2030. In an effort to capture how research is contributing to move the needle on those challenges, we earlier have made an initial classification model than enables to quickly identify what research output is related to what {SDG}. (This Aurora {SDG} dashboard is the initial outcome as proof of practice.) The initiative started from the Aurora Universities Network in 2017, in the working group "Societal Impact and Relevance of Research", to investigate and to make visible 1. what research is done that are relevant to topics or challenges that live in society (for the proof of practice this has been scoped down to the {SDGs}), and 2. what the effect or impact is of implementing those research outcomes to those societal challenges (this also have been scoped down to research output being cited in policy documents from national and local governments an {NGO}'s). Context of this dataset {\textbar} classification model improvement workflow The classification model we have used are 17 different search queries on the Scopus database. {SDG} search queries version 4.0 ({SQv}4) have been created, Published here: Search Queries for "Mapping Research Output to the Sustainable Development Goals ({SDGs})" v4.0 by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3817443 A survey has been distributed to senior researchers to test the robustness of {SQv}4. Published here: Survey data of "Mapping Research output to the Sustainable Development Goals {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3798385 This text analysis has been made as one of the inputs to improve the classification model. Published here: Text Analyses of Survey Data on "Mapping Research Output to the Sustainable Development Goals {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3832090 Improved {SDG} search queries version 5.0 ({SQv}5) have been created, Published here: Search Queries for "Mapping Research Output to the Sustainable Development Goals ({SDGs})" v5.0 by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3817445 Methods used to do the text analysis Term Extraction: after text normalisation (stemming, etc) we extracted 2 terms in bigrams and trigrams that co-occurred the most per document, in the title, abstract and keyword Contrast analysis: the co-occurring terms in publications (title, abstract, keywords), of the papers that respondents have indicated relate to this {SDG} (y-axis: True), and that have been rejected (x-axis: False). In the top left you'll see term co-occurrences that a clearly relate to this {SDG}. The bottom-right are terms that are appear in papers that have been rejected for this {SDG}. The top-right terms appear frequently in both and cannot be used to discriminate between the two groups. Network map: This diagram shows the cluster-network of terms co-occurring in the publications related to this {SDG}, selected by the respondents (accepted publications only). Topic model: This diagram shows the topics, and the related terms that make up that topic. The number of topics is related to the number of of targets of this {SDG}. Contingency matrix: This diagram shows the top 10 of co-occurring terms that correlate the most. Software used to do the text analyses {CorTexT}: The {CorTexT} Platform is the digital platform of {LISIS} Unit and a project launched and sustained by {IFRIS} and {INRAE}. This platform aims at empowering open research and studies in humanities about the dynamic of science, technology, innovation and knowledge production. Resource with interactive visualisations Based on the text analysis data we have created a website that puts all the {SDG} interactive diagrams together. For you to scrall through. https://sites.google.com/vu.nl/sdg-survey-analysis-results/ Data set content In the dataset root you'll find the following folders and files: /sdg01-17/ This contains the text analysis for all the individual {SDG} surveys. /methods/ This contains the step-by-step explanations of the text analysis methods using Cortext. /images/ images of the results used in this {README}.md. {LICENSE}.md terms and conditions for reusing this data. {README}.md description of the dataset; each subfolders contains a {README}.md file to futher describe the content of each sub-folder. Inside an /sdg01-17/-folder you'll find the following: This contains the step-by-step explanations of the text analysis methods using Cortext. /sdg01-17/sdg04-sdg-survey-selected-publications-combined.db his contains the title, abstract, keywords, fo the publications in the survey, including the and accept or rejection status and the number of respondents /sdg01-17/sdg04-sdg-survey-selected-publications-combined-accepted-accepted-custom-filtered.db same as above, but only the accepted papers /sdg01-17/extracted-terms-list-top1000.csv the aggregated list of co-occuring terms (bigrams and trigrams) extracted per paper. /sdg01-17/contrast-analysis/ This contains the data and visualisation of the terms appearing in papers that have been accepted (true) and rejected (false) to be relating to this {SDG}. /sdg01-17/topic-modelling/ This contains the data and visualisation of the terms clustered in the same number of topics as there are 'targets' within that {SDG}. /sdg01-17/network-mapping/ This contains the data and visualisation of the terms clustered in co-occuring proximation of appearance in papers /sdg01-17/contingency-matrix/ This contains the data and visualisation of the top 10 terms co-occuring note: the .csv files are actually tab-separated. Contribute and improve the {SDG} Search Queries We welcome you to join the Github community and to fork, branch, improve and make a pull request to add your improvements to the new version of the {SDG} queries. https://github.com/Aurora-Network-Global/sdg-queries},
	publisher = {Zenodo},
	author = {Vanderfeesten, Maurice and Spielberg, Eike and Hasse, Linda},
	urldate = {2021-04-15},
	date = {2020-05-18},
	doi = {10.5281/zenodo.3832090},
	note = {type: dataset},
	keywords = {Contingency matrix, Contrast analysis, Cortext, Network mapping, {SDG}, Sustainable Development Goals, Term extraction, Text analysis, Topic modelling},
	file = {Zenodo Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\QEYAIGBT\\3832090.html:text/html}
}

@misc{vanderfeesten_survey_2020,
	title = {Survey data of "Mapping Research Output to the Sustainable Development Goals ({SDGs})"},
	url = {https://zenodo.org/record/3813230},
	abstract = {This dataset contains information on what papers and concepts researchers find relevant to map domain specific research output to the 17 Sustainable Development Goals ({SDGs}). Sustainable Development Goals are the 17 global challenges set by the United Nations. Within each of the goals specific targets and indicators are mentioned to monitor the progress of reaching those goals by 2030. In an effort to capture how research is contributing to move the needle on those challenges, we earlier have made an initial classification model than enables to quickly identify what research output is related to what {SDG}. (This Aurora {SDG} dashboard is the initial outcome as proof of practice.) In order to validate our current classification model (on soundness/precision and completeness/recall), and receive input for improvement, a survey has been conducted to capture expert knowledge from senior researchers in their research domain related to the {SDG}. The survey was open to the world, but mainly distributed to researchers from the Aurora Universities Network. The survey was open from October 2019 till January 2020, and captured data from 244 respondents in Europe and North America. 17 surveys were created from a single template, where the content was made specific for each {SDG}. Content, like a random set of publications, of each survey was ingested by a data provisioning server. That collected research output metadata for each {SDG} in an earlier stage. It took on average 1 hour for a respondent to complete the survey. The outcome of the survey data can be used for validating current and optimizing future {SDG} classification models for mapping research output to the {SDGs}. The survey contains the following questions (see inside dataset for exact wording): Are you familiar with this {SDG}? Respondents could only proceed if they were familiar with the targets and indicators of this {SDG}. Goal of this question was to weed out un knowledgeable respondents and to increase the quality of the survey data. Suggest research papers that are relevant for this {SDG} (upload list) This question, to provide a list, was put first to reduce influenced by the other questions. Goal of this question was to measure the completeness/recall of the papers in the result set of our current classification model. (To lower the bar, these lists could be provided by either uploading a file from a reference manager (preferred) in .ris of bibtex format, or by a list of titles. This heterogenous input was processed further on by hand into a uniform format.) Select research papers that are relevant for this {SDG} (radio buttons: accept, reject) A randomly selected set of 100 papers was injected in the survey, out of the full list of thousands of papers in the result set of our current classification model. Goal of this question was to measure the soundness/precision of our current classification model. Select and Suggest Keywords related to {SDG} (checkboxes: accept {\textbar} text field: suggestions) The survey was injected with the top 100 most frequent keywords that appeared in the metadata of the papers in the result set of the current classification model. respondents could select relevant keywords we found, and add ones in a blank text field. Goal of this question was to get suggestions for keywords we can use to increase the recall of relevant papers in a new classification model. Suggest {SDG} related glossaries with relevant keywords (text fields: url) Open text field to add {URL} to lists with hundreds of relevant keywords related to this {SDG}. Goal of this question was to get suggestions for keywords we can use to increase the recall of relevant papers in a new classification model. Select and Suggest Journals fully related to {SDG} (checkboxes: accept {\textbar} text field: suggestions) The survey was injected with the top 100 most frequent journals that appeared in the metadata of the papers in the result set of the current classification model. Respondents could select relevant journals we found, and add ones in a blank text field. Goal of this question was to get suggestions for complete journals we can use to increase the recall of relevant papers in a new classification model. Suggest improvements for the current queries (text field: suggestions per target) We showed respondents the queries we used in our current classification model next to each of the targets within the goal. Open text fields were presented to change, add, re-order, delete something (keywords, boolean operators, etc. ) in the query to improve it in their opinion. Goal of this question was to get suggestions we can use to increase the recall and precision of relevant papers in a new classification model. In the dataset root you'll find the following folders and files: /00-survey-input/ This contains the survey questions for all the individual {SDGs}. It also contains lists of {EIDs} categorised to the {SDGs} we used to make randomized selections from to present to the respondents. /01-raw-data/ This contains the raw survey output. (Excluding privacy sensitive information for public release.) This data needs to be combined with the data on the provisioning server to make sense. /02-aggregated-data/ This data is where individual responses are aggregated. Also the survey data is combined with the provisioning server, of all sdg surveys combined, responses are aggregated, and split per question type. /03-scripts/ This contains scripts to split data, and to add descriptive metadata for text analysis in a later stage. /04-processed-data/ This is the main final result that can be used for further analysis. Data is split by {SDG} into subdirectories, in there you'll find files per question type containing the aggregated data of the respondents. /images/ images of the results used in this {README}.md. {LICENSE}.md terms and conditions for reusing this data. {README}.md description of the dataset; each subfolders contains a {README}.md file to futher describe the content of each sub-folder. In the /04-processed-data/ you'll find in each {SDG} sub-folder the following files.: {SDG}-survey-questions.pdf This file contains the survey questions {SDG}-survey-questions.doc This file contains the survey questions {SDG}-survey-respondents-per-sdg.csv Basic information about the survey and responses {SDG}-survey-city-heatmap.csv Origin of the respondents per {SDG} survey {SDG}-survey-suggested-publications.txt Formatted list of research papers researchers have uploaded or listed they want to see back in the result-set for this {SDG}. {SDG}-survey-suggested-publications-with-eid-match.csv same as above, only matched with an {EID}. {EIDs} are matched my Elsevier's internal fuzzy matching algorithm. Only papers with high confidence are show with a match of an {EID}, referring to a record in Scopus. {SDG}-survey-selected-publications-accepted.csv Based on our previous result set of papers, researchers were presented random samples, they selected papers they believe represent this {SDG}. ({TRUE}=accepted) {SDG}-survey-selected-publications-rejected.csv Based on our previous result set of papers, researchers were presented random samples, they selected papers they believe not to represent this {SDG}. ({FALSE}=rejected) {SDG}-survey-selected-keywords.csv Based on our previous result set of papers, we presented researchers the keywords that are in the metadata of those papers, they selected keywords they believe represent this {SDG}. {SDG}-survey-unselected-keywords.csv As "selected-keywords", this is the list of keywords that respondents have not selected to represent this {SDG}. {SDG}-survey-suggested-keywords.csv List of keywords researchers suggest to use to find papers related to this {SDG} {SDG}-survey-glossaries.csv List of glossaries, containing keywords, researchers suggest to use to find papers related to this {SDG} {SDG}-survey-selected-journals.csv Based on our previous result set of papers, we presented researchers the journals that are in the metadata of those papers, they selected journals they believe represent this {SDG}. {SDG}-survey-unselected-journals.csv As "selected-journals", this is the list of journals that respondents have not selected to represent this {SDG}. {SDG}-survey-suggested-journals.csv List of journals researchers suggest to use to find papers related to this {SDG} {SDG}-survey-suggested-query.csv List of query improvements researchers suggest to use to find papers related to this {SDG} Cite as: Survey data of "Mapping Research output to the {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3798385 Attribute as: Survey data of "Mapping Research output to the {SDGs}" by Aurora Universities Network ({AUR}); Alessandro Arienzo ({UNA}); Roberto Delle Donne ({UNA}); Ignasi Salvadó Estivill ({URV}); José Luis González Ugarte ({URV}); Didier Vercueil ({UGA}); Nykohla Strong ({UAB}); Eike Spielberg ({UDE}); Felix Schmidt ({UDE}); Linda Hasse ({UDE}); Ane Sesma ({UEA}); Baldvin Zarioh ({UIC}); Friedrich Gaigg ({UIN}); René Otten ({VUA}); Nicolien van der Grijp ({VUA}); Yasin Gunes ({VUA}); Peter van den Besselaar ({VUA}); Joeri Both ({VUA}); Maurice Vanderfeesten ({VUA}); is licensed under a Creative Commons Attribution 4.0 International License. https://aurora-network.global/project/sdg-analysis-bibliometrics-relevance/},
	publisher = {Zenodo},
	author = {Vanderfeesten, Maurice and Spielberg, Eike and Gunes, Yassin},
	urldate = {2021-04-15},
	date = {2020-05-11},
	doi = {10.5281/zenodo.3813230},
	note = {type: dataset},
	keywords = {Aurora Universites, Classification model, Mapping Research, Matching Research, Questionnaire, Recall, Recision, {SDG}, Survey, Sustainable Development Goals},
	file = {Vanderfeesten et al_2020_Survey data of Mapping Research Output to the Sustainable Development Goals.pdf:C\:\\Users\\mauri\\Zotero\\storage\\JYDDKEHA\\Vanderfeesten et al_2020_Survey data of Mapping Research Output to the Sustainable Development Goals.pdf:application/pdf}
}

@article{jayabalasingham_identifying_2019,
	title = {Identifying research supporting the United Nations Sustainable Development Goals},
	volume = {1},
	url = {10.17632/87txkw7khs.1},
	doi = {10.17632/87txkw7khs.1},
	abstract = {In an effort to identify research that supports the {UN} {SDGs}, Elsevier has generated a set of Scopus queries related to each of the {SDGs}. In this dataset, you will find documentation describing how each of the Scopus queries were created along with a collated list of the queries.},
	author = {Jayabalasingham, Bamini and Boverhof, Roy and Agnew, Kevin and Klein, L.},
	urldate = {2021-04-15},
	date = {2019-10-22},
	year = {2019},
	journal = {Mendeley Data},
	langid = {english},
	note = {Publisher: Mendeley},
	file = {Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\8QTQDNKP\\1.html:text/html}
}

@article{rafols_visualising_2021,
	title = {Visualising plural mappings of science for Sustainable Development Goals ({SDGs})},
	url = {https://osf.io/yfqbd},
	abstract = {Analysts are rapidly developing methods to map publications to {SDGs} in the face of policy demands. However, as reported by Armitage et al. (2020), a high degree of inconsistency is found when comparing the bibliometric corpora obtained with different approaches. These inconsistencies are not due to minor technical issues, but instead they represent different interpretations of {SDGs}. Given the variety of understandings regarding the relationship between research and {SDGs}, we propose that bibliometrics analysts should not assume that there is one single, preferred or consensus way of mapping {SDGs} to publications. We propose instead that, since different stakeholders have contrasting views about the relationships between science and {SDGs}, the contribution of bibliometrics should be to provide a plural landscape for stakeholders to explore their own views. We describe here the beta-version of an interactive platform that allows stakeholders to scrutinise in a global map of science the clusters potentially related to {SDGs}.},
	institution = {{SocArXiv}},
	journal = {{SocArXiv}},
	type = {preprint},
	author = {Rafols, Ismael and Noyons, Ed and Confraria, Hugo and Ciarli, Tommaso},
	urldate = {2021-05-19},
	date = {2021-05-10},
	year = {2021},
	langid = {english},
	doi = {10.31235/osf.io/yfqbd},
	file = {Rafols et al. - 2021 - Visualising plural mappings of science for Sustain.pdf:C\:\\Users\\mauri\\Zotero\\storage\\8IGZ6PPY\\Rafols et al. - 2021 - Visualising plural mappings of science for Sustain.pdf:application/pdf}
}

@inproceedings{zhang_matching_2020,
	title = {Matching Research Publications to the United Nations’ Sustainable Development Goals by Multi-Label-Learning with Hierarchical Categories},
	url = {10.1109/DSAA49011.2020.00066},
	doi = {10.1109/DSAA49011.2020.00066},
	abstract = {In 2015 the United Nations proposed the Sustainable Development Goals ({SDGs}), a set of universal goals for meeting the urgent environmental, political and economic challenges in the world. Universities play an important role to support and contribute to the {SDGs} mainly through education and research. To evaluate the contributions through research, universities aim at relating their scientific publications to {SDGs}, and automatically quantify the connectedness of these publications to the detailed targets and the unique indicators under {SDGs}. In this paper, we apply deep learning techniques to estimate the unknown indicators (third level) and targets (second level) for each publication, and output all its possible goals (first level). Specifically, we first exploit the dependency of categories at different levels (goals, targets, and indicators) to extract the dependent label features. Then we calculate the degree of matching between categories and publications in a bottom-up way and design a hierarchical structure to transfer such matching information level by level until obtaining the predicted {SDGs} of the publications. This is the first application of a deep learning method on this {SDG} prediction task and our experiments clearly demonstrate the good performance of our model on this real-world {SDGs} matching task, the extraction of key information as well as the prediction of potential sub-categories. As auxiliary analysis, we visualize the extraction of key semantic information and the probability of the hierarchical {SDG} categories.},
	eventtitle = {2020 {IEEE} 7th International Conference on Data Science and Advanced Analytics ({DSAA})},
	pages = {516--525},
	booktitle = {2020 {IEEE} 7th International Conference on Data Science and Advanced Analytics ({DSAA})},
	author = {Zhang, Rui and Vignes, Maéva and Steiner, Ulrich and Zimek, Arthur},
	date = {2020-10},
	year = {2020},
	keywords = {Data models, Data visualization, Deep learning, Hierarchical category, Label-aware classification, Matching model, Prediction, Predictive models, Semantics, Sustainable development, Task analysis, The Sustainable Development Goals ({SDGs})},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\mauri\\Zotero\\storage\\VVG2R9JZ\\9260025.html:text/html}
}

@article{rivest_improving_2021,
	title = {Improving the Scopus and Aurora queries to identify research that supports the United Nations Sustainable Development Goals ({SDGs}) 2021},
	volume = {2},
	url = {10.17632/9sxdykm8s4.2},
	doi = {10.17632/9sxdykm8s4.2},
	abstract = {The United Nations Sustainable Development Goals ({SDGs}) challenge the global community to build a world where no one is left behind. Since 2018, Elsevier have generated {SDG} search queries to help researchers and institutions track and demonstrate progress towards the targets of the United Nations Sustainable Development Goals ({SDGs}). At the end of 2018, Elsevier worked on 2 versions of the {SDG} queries. One version was created by the Elsevier Analytical Services group and another by the Science-Metrix group, who had recently become part of Elsevier. At that time Science-Metrix was creating queries for 5 of the 16 {SDGs}, as part of pro-bono work for {UNESCO}. In 2020 inspired by the earlier queries, Elsevier, through its Science-Metrix group, used a new approach to mapping publications to the {SDGs}. Taking customer feedback into account, they significantly increased the number of search terms used to define each {SDG}. Those queries were then complemented by a machine learning model, which helped increase the recall by approximately 10\%. As a result, this year’s “Elsevier 2021 {SDG} mapping” captures on average twice as many articles as the 2020 version, while keeping precision above 80\%. The mapping also has a better overlap with {SDG} queries from other independent projects. Times Higher Education ({THE}) are using the “Elsevier 2021 {SDG} mapping” as part of their 2021 Impact Rankings. The documentation below, describes the methods used and shares the queries.},
	author = {Rivest, Maxime and Kashnitsky, Yury and Bédard-Vallée, Alexandre and Campbell, David and Khayat, Paul and Labrosse, Isabelle and Pinheiro, Henrique and Provençal, Simon and Roberge, Guillaume and James, Chris},
	urldate = {2021-05-19},
	date = {2021-04-05},
	year = {2021},
	journal = {Mendeley},
	langid = {english},
	note = {Publisher: Mendeley},
	file = {Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\YJV8RA4A\\2.html:text/html}
}


@misc{vanderfeesten_search_2020,
	title = {Search Queries for "Mapping Research Output to the Sustainable Development Goals ({SDGs})" v5.0.2},
	url = {https://zenodo.org/record/4883250},
	abstract = {This package contains machine readable (xml) search queries, for the Scopus publication database, to find domain specific research output that are related to the 17 Sustainable Development Goals ({SDGs}). [ {SDG} {QUERIES} {PAGES} ] [ {PROJECT} {WEBSITE} ] [ {FORK} {ON} {GITHUB} ] Sustainable Development Goals are the 17 global challenges set by the United Nations. Within each of the goals specific targets and indicators are mentioned to monitor the progress of reaching those goals by 2030. In an effort to capture how research is contributing to move the needle on those challenges, we earlier have made an initial classification model than enables to quickly identify what research output is related to what {SDG}. (This Aurora {SDG} dashboard is the initial outcome as proof of practice.) The initiative started from the Aurora Universities Network in 2017, in the working group "Societal Impact and Relevance of Research", to investigate and to make visible 1. what research is done that are relevant to topics or challenges that live in society (for the proof of practice this has been scoped down to the {SDGs}), and 2. what the effect or impact is of implementing those research outcomes to those societal challenges (this also have been scoped down to research output being cited in policy documents from national and local governments an {NGO}'s). The classification model we have used are 17 different search queries on the Scopus database. The search queries are elegant constructions with keyword combinations and boolean operators, in the syntax specific to the Scopus Query Language. We have used Scopus because it covers more research area's that are relevant to the {SDG}'s, and we could filter much easier the Aurora Institutions. Versions Different versions of the search queries have been made over the past years to improve the precision (soundness) and recall (completeness) of the results. The queries have been made in a team effort by several bibliometric experts from the Aurora Universities. Each one did two or 3 {SDG}'s, and than reviewed each other's work. v1.0 January 2018 Initial 'strict' version. In this version only the terms were used that appear in the {SDG} policy text of the targets and indicators defined by the {UN}. At this point we have been aware of the {SDSN} Compiled list of keywords, and used them as inspiration. Rule of thumb was to use keyword-combination searches as much as possible rather than single-keyword searches, to be more precise rather than to yield large amounts of false positive papers. Also we did not use the inverse or '{NOT}' operator, to prevent removing true positives from the result set. This version has not been reviewed by peers. Download from: {GitHub} / Zenodo v2.0 March 2018 Reviewed 'strict' version. Same as version 1, but now reviewed by peers. Download from: {GitHub} / Zenodo v3.0 May 2019 'echo chamber' version. We noticed that using strictly the terms that policy makers of the {UN} use in the targets and indicators, that much of the research that did not use that specific terms was left out in the result set. (eg. "mortality" vs "deaths") To increase the recall, without reducing precision of the papers in the results, we added keywords that were obvious synonyms and antonyms to the existing 'strict' keywords. This was done based on the keywords that appeared in papers in the result set of version 2. This creates an 'echo chamber', that results in more of the same papers. Download from: {GitHub} / Zenodo v4.0 August 2019 uniform 'split' version. Over the course of the years, the {UN} changed and added Targets and indicators. In order to keep track of if we missed a target, we have split the queries to match the targets within the goals. This gives much more control in maintenance of the queries. Also in this version the use of brackets, quotation marks, etc. has been made uniform, so it also works with {API}'s, and not only with {GUI}'s. His version has been used to evaluate using a survey, to get baseline measurements for the precision and recall. Published here: Survey data of "Mapping Research output to the {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3798385. Download from: {GitHub} / Zenodo v5.0 June 2020 'improved' version. In order to better reflect academic representation of research output that relate to the {SDG}'s, we have added more keyword combinations to the queries to increase the recall, to yield more research papers related to the {SDG}'s, using academic terminology. We mainly used the input from the Survey data of "Mapping Research output to the {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3798385. We ran several text analyses: Frequent term combination in title and abstracts from Suggested papers, and in selected (accepted) papers, suggested journals, etc.found in this data set Spielberg, Eike, \& Hasse, Linda. (2020). Text Analyses of Survey Data on "Mapping Research Output to the Sustainable Development Goals ({SDGs})" (Version 1.0) [Data set]. Zenodo http://doi.org/10.5281/zenodo.3832090 .  Secondly we got inspiration out of the Elsevier {SDG} queries Jayabalasingham, Bamini; Boverhof, Roy; Agnew, Kevin; Klein, Lisette (2019), “Identifying research supporting the United Nations Sustainable Development Goals”, Mendeley Data, v1 https://dx.doi.org/10.17632/87txkw7khs.1. And thirdly we got inspiration from this controlled vocabulary containing closely related terms. Duran-Silva, Nicolau, Fuster, Enric, Massucci, Francesco Alessandro, \& Quinquillà, Arnau. (2019). A controlled vocabulary defining the semantic perimeter of Sustainable Development Goals (Version 1.2) [Data set]. Zenodo. doi.org/10.5281/zenodo.3567769 Download from: {GitHub} / Zenodo Contribute and improve the {SDG} Search Queries We welcome you to join the Github community and to fork, improve and make a pull request to add your improvements to the new version of the {SDG} queries. https://aurora-network-global.github.io/sdg-queries/},
	publisher = {Zenodo},
	author = {Vanderfeesten, Maurice and Otten, René and Spielberg, Eike},
	urldate = {2021-06-07},
	date = {2020-07-02},
	doi = {10.5281/zenodo.4883250},
	keywords = {Classification model, Controlled vocabulary, {SCOPUS}, {SDG}, Search Queries, Sustainable Development Goals, Text indexing},
	file = {Zenodo Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\HQZ22BCB\\4883250.html:text/html}
}

@misc{vanderfeesten_search_2019,
	title = {Search Queries for "Mapping Research Output to the Sustainable Development Goals ({SDGs})" v4.0},
	url = {https://zenodo.org/record/3817443},
	abstract = {This package contains machine readable (xml) search queries, for the Scopus publication database, to find domain specific research output that are related to the 17 Sustainable Development Goals ({SDGs}). Sustainable Development Goals are the 17 global challenges set by the United Nations. Within each of the goals specific targets and indicators are mentioned to monitor the progress of reaching those goals by 2030. In an effort to capture how research is contributing to move the needle on those challenges, we earlier have made an initial classification model than enables to quickly identify what research output is related to what {SDG}. (This Aurora {SDG} dashboard is the initial outcome as proof of practice.) The initiative started from the Aurora Universities Network in 2017, in the working group "Societal Impact and Relevance of Research", to investigate and to make visible 1. what research is done that are relevant to topics or challenges that live in society (for the proof of practice this has been scoped down to the {SDGs}), and 2. what the effect or impact is of implementing those research outcomes to those societal challenges (this also have been scoped down to research output being cited in policy documents from national and local governments an {NGO}'s). The classification model we have used are 17 different search queries on the Scopus database. The search queries are elegant constructions with keyword combinations and boolean operators, in the syntax specific to the Scopus Query Language. We have used Scopus because it covers more research area's that are relevant to the {SDG}'s, and we could filter much easier the Aurora Institutions. Versions Different versions of the search queries have been made over the past years to improve the precision (soundness) and recall (completeness) of the results. The queries have been made in a team effort by several bibliometric experts from the Aurora Universities. Each one did two or 3 {SDG}'s, and than reviewed each other's work. v1.0 January 2018 Initial 'strict' version. In this version only the terms were used that appear in the {SDG} policy text of the targets and indicators defined by the {UN}. At this point we have been aware of the {SDSN} Compiled list of keywords, and used them as inspiration. Rule of thumb was to use keyword-combination searches as much as possible rather than single-keyword searches, to be more precise rather than to yield large amounts of false positive papers. Also we did not use the inverse or '{NOT}' operator, to prevent removing true positives from the result set. This version has not been reviewed by peers. Download from: {GitHub} / Zenodo v2.0 March 2018 Reviewed 'strict' version. Same as version 1, but now reviewed by peers. Download from: {GitHub} / Zenodo v3.0 May 2019 'echo chamber' version. We noticed that using strictly the terms that policy makers of the {UN} use in the targets and indicators, that much of the research that did not use that specific terms was left out in the result set. (eg. "mortality" vs "deaths") To increase the recall, without reducing precision of the papers in the results, we added keywords that were obvious synonyms and antonyms to the existing 'strict' keywords. This was done based on the keywords that appeared in papers in the result set of version 2. This creates an 'echo chamber', that results in more of the same papers. Download from: {GitHub} / Zenodo v4.0 August 2019 uniform 'split' version. Over the course of the years, the {UN} changed and added Targets and indicators. In order to keep track of if we missed a target, we have split the queries to match the targets within the goals. This gives much more control in maintenance of the queries. Also in this version the use of brackets, quotation marks, etc. has been made uniform, so it also works with {API}'s, and not only with {GUI}'s. His version has been used to evaluate using a survey, to get baseline measurements for the precision and recall. Published here: Survey data of "Mapping Research output to the {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3798385. Download from: {GitHub} / Zenodo v5.0 June 2020 'improved' version. In order to better reflect academic representation of research output that relate to the {SDG}'s, we have added more keyword combinations to the queries to increase the recall, to yield more research papers related to the {SDG}'s, using academic terminology. We mainly used the input from the Survey data of "Mapping Research output to the {SDGs}" by Aurora Universities Network ({AUR}) doi:10.5281/zenodo.3798385. We ran several text analyses: Frequent term combination in title and abstracts from Suggested papers, and in selected (accepted) papers, suggested journals, etc. Secondly we got inspiration out of the Elsevier {SDG} queries Jayabalasingham, Bamini; Boverhof, Roy; Agnew, Kevin; Klein, Lisette (2019), “Identifying research supporting the United Nations Sustainable Development Goals”, Mendeley Data, v1 https://dx.doi.org/10.17632/87txkw7khs.1. Download from: {GitHub} / Zenodo Contribute and improve the {SDG} Search Queries We welcome you to join the Github community and to fork, improve and make a pull request to add your improvements to the new version of the {SDG} queries. https://github.com/Aurora-Network-Global/sdg-queries},
	publisher = {Zenodo},
	author = {Vanderfeesten, Maurice and Otten, René and Spielberg, Eike},
	urldate = {2021-06-07},
	date = {2019-08-21},
	doi = {10.5281/zenodo.3817443},
	keywords = {Classification model, Controlled vocabulary, {SCOPUS}, {SDG}, Search Queries, Sustainable Development Goals, Text indexing},
	file = {Zenodo Snapshot:C\:\\Users\\mauri\\Zotero\\storage\\IPL69PZM\\3817443.html:text/html}
}

@unpublished{vanderfeesten_societal_2017,
	location = {Norwich},
	title = {Societal Relevant Impact : Potential analysis for Aurora-Network university leaders to strengthen collaboration on societal challenges},
	url = {https://zenodo.org/record/1045839},
	shorttitle = {Societal Relevant Impact},
	abstract = {Presentation at the Societal Impact and Relevance of Research workshop, {AurorA} conference, Norwich, 2017-11-09 Including the report and the data. Analysis file: "Official Revised List of Global {SDG} Indicators\_17.04.2017\_Web.xlsx"},
	note = {Aurora-Network Norwich 2017 (Aurora2017)},
	author = {Vanderfeesten, Maurice and Otten, René},
	urldate = {2021-06-07},
	date = {2017-11-03},
	doi = {10.5281/zenodo.1045839},
	keywords = {Altmetrics, Aurora, Research Excellence, {SDG}, {SEP}, Societal Challenge, Sustainable Development},
	file = {Vanderfeesten_Otten_2017_Societal Relevant Impact.pdf:C\:\\Users\\mauri\\Zotero\\storage\\HDBLNT36\\Vanderfeesten_Otten_2017_Societal Relevant Impact.pdf:application/pdf}
}